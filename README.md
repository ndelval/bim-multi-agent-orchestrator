# AI Agents Unified Framework

A production-ready, unified AI agents framework combining multiple best-in-class components for building sophisticated multi-agent systems with long-term memory, advanced reasoning, and scalable orchestration.

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)

---

## ğŸ¯ Overview

This project integrates four powerful production-ready components into a cohesive framework for building advanced AI agent systems:

### Core Components

1. **[PraisonAI](PraisonAI/)** - Multi-agent framework with self-reflection

   - 100+ LLM integrations (OpenAI, Anthropic, Groq, Ollama, etc.)
   - Self-reflection with configurable iteration cycles (1-3 iterations)
   - Guardrails system for output validation
   - Multiple execution patterns: sequential, hierarchical, parallel
   - 100+ examples and test cases

2. **[Mem0](mem0/)** - Intelligent memory layer for AI

   - Multi-level memory: user, session, agent scopes
   - Graph database support (Neo4j, Memgraph) for entity relationships
   - Temporal memory with automatic decay
   - **Performance**: +26% accuracy, 91% faster, 90% fewer tokens vs full context
   - Cross-session memory persistence

3. **[Orchestrator](orchestrator/)** - Scalable agent orchestration system

   - **NEW**: Class-based architecture replacing monolithic functions
   - Parallel execution with DAG-based workflow engine
   - Three memory providers: Hybrid (recommended), RAG, Mem0
   - Dual backend support: PraisonAI (legacy) + LangGraph (modern)
   - GraphRAG tools for memory-augmented retrieval
   - Rich CLI with real-time progress tracking

4. **[Tree-of-Thought-LLM](tree-of-thought-llm/)** - Advanced reasoning system
   - Multiple search strategies: BFS, DFS, greedy, beam search
   - StateGraph generation for complex workflow planning
   - Integrated with orchestrator for dynamic task assignment
   - Configurable tree depth and branching factor

---

## ğŸ“Š System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AI Agents Unified Framework                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    Orchestrator                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚Agent Factory â”‚  â”‚Task Factory  â”‚  â”‚Memory Managerâ”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚Workflow DAG  â”‚  â”‚Router System â”‚  â”‚GraphRAG Tool â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Memory Layer (Mem0 + Hybrid)                â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚ â”‚
â”‚  â”‚  â”‚Vector Storeâ”‚  â”‚Lexical FTS5â”‚  â”‚Graph Store â”‚        â”‚ â”‚
â”‚  â”‚  â”‚ (ChromaDB) â”‚  â”‚  (SQLite)  â”‚  â”‚  (Neo4j)   â”‚        â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚          Agent Execution (PraisonAI + LangGraph)         â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚  â”‚  â”‚ Self-Reflection      â”‚  â”‚  Guardrails System   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚ (1-3 iterations)     â”‚  â”‚  (Validation)        â”‚    â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚      Advanced Planning (Tree-of-Thought)                 â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚   BFS    â”‚  â”‚   DFS    â”‚  â”‚  Greedy  â”‚  â”‚  Beam   â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- (Optional) Neo4j 4.0+ for graph memory
- (Optional) Qdrant for high-performance vector search

### Installation

#### 1. Basic Setup (Orchestrator + Mem0 + PraisonAI)

```bash
# Clone repository
git clone <repository-url>
cd PruebasMultiAgent

# Install with uv (recommended for faster dependency resolution)
pip install uv
uv pip install -e .[all-basic]

# Or use standard pip
pip install -e .[all-basic]
```

#### 2. Full Installation (All Features)

```bash
# Complete setup with all providers and interfaces
uv pip install -e .[mem0-full,praison-full]

# Or for development with testing tools
uv pip install -e .[all-mem0]
```

#### 3. Feature-Specific Installation

```bash
# Memory layer with all providers
uv pip install -e .[mem0-full]

# PraisonAI with all interfaces (UI, code, chat)
uv pip install -e .[praison-full]

# GraphRAG with ingestion pipeline
uv pip install -e .[graphrag-ingestion]
```

### Environment Configuration

Create `.env` file in project root:

```bash
# LLM Configuration
OPENAI_API_KEY=your_key_here
OPENAI_BASE_URL=https://api.openai.com/v1  # Optional: For Ollama/Groq

# Memory Configuration (Hybrid Provider)
ORCH_MEMORY_PROVIDER=hybrid
HYBRID_VECTOR_PATH=.praison/hybrid_chroma
HYBRID_LEXICAL_DB_PATH=.praison/hybrid_lexical.db
NEO4J_URL=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# Mem0 Configuration (Alternative)
MEM0_GRAPH_URL=bolt://localhost:7687
MEM0_VECTOR_PROVIDER=qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333
```

---

## ğŸ’¡ Usage Examples

### 1. Orchestrator Chat CLI (Quickest Start)

```bash
# Start interactive chat with hybrid memory
python -m orchestrator.cli chat --memory-provider hybrid --verbose

# Use simple RAG provider (no Neo4j needed)
python -m orchestrator.cli chat --memory-provider rag

# Check memory configuration
python -m orchestrator.cli memory-info --memory-provider hybrid
```

**Example Conversation:**

```
User: Research best practices for API authentication
Router: [Analyzes query] â†’ Decision: "analysis" (Multi-agent research)
Researcher: [Searches web + GraphRAG] â†’ Gathers OAuth 2.0, JWT best practices
Analyst: [Analyzes findings] â†’ Identifies security patterns
Planner: [Creates plan] â†’ 5-step implementation guide
StandardsAgent: [Reviews] â†’ Validates completeness
Final Answer: [Formatted response with citations]
```

### 2. Document Ingestion (GraphRAG Pipeline)

```bash
# Ingest PDF documents into hybrid memory
python -m orchestrator.ingestion.sample_loader \
  --input docs/api_security_guide.pdf \
  --metadata manifests/security_metadata.yaml \
  --memory-provider hybrid
```

**Metadata Format (`manifests/security_metadata.yaml`):**

```yaml
document_id: api_security_001
section_title: OAuth 2.0 Implementation
tags:
  - security
  - api
  - authentication
source_url: https://example.com/docs/security
author: Security Team
date: 2024-01-01
```

### 3. Programmatic Orchestrator Usage

```python
from orchestrator import Orchestrator, OrchestratorConfig
from orchestrator.core.config import AgentConfig, TaskConfig, MemoryConfig

# 1. Create configuration
config = OrchestratorConfig(
    name="APISecurityWorkflow",
    process="workflow",  # DAG-based parallel execution
    memory=MemoryConfig(provider="hybrid")
)

# 2. Add agents
config.agents.extend([
    AgentConfig(
        name="SecurityResearcher",
        role="Security Research Specialist",
        goal="Research security vulnerabilities and best practices",
        backstory="Expert in API security and OWASP standards",
        instructions="Search web and memory for security information",
        tools=["duckduckgo", "graphrag"],
        llm="gpt-4o-mini"
    ),
    AgentConfig(
        name="SecurityAnalyst",
        role="Security Analysis Expert",
        goal="Analyze security findings and identify risks",
        backstory="Experienced security analyst with threat modeling skills",
        instructions="Analyze research and identify security risks",
        tools=["graphrag"],
        llm="gpt-4o-mini"
    )
])

# 3. Add tasks with dependencies
config.tasks.extend([
    TaskConfig(
        name="research_task",
        description="Research API authentication security best practices",
        expected_output="Comprehensive research findings with citations",
        agent="SecurityResearcher",
        is_start=True,  # Start task for workflow
        async_execution=True  # Can run in parallel with other start tasks
    ),
    TaskConfig(
        name="analysis_task",
        description="Analyze security findings and create risk assessment",
        expected_output="Security risk assessment report",
        agent="SecurityAnalyst",
        context=["research_task"],  # Depends on research task
    )
])

# 4. Execute workflow
orchestrator = Orchestrator(config)
result = orchestrator.run_sync()

print(result)
```

### 4. Dynamic Planning with ToT

```python
from orchestrator import Orchestrator, OrchestratorConfig
from orchestrator.core.config import AgentConfig

# Setup orchestrator with agents
config = OrchestratorConfig(name="DynamicWorkflow")
config.agents = [...]  # Add agents

orchestrator = Orchestrator(config)
orchestrator.initialize()

# Generate tasks dynamically from user prompt
orchestrator.plan_from_prompt(
    prompt="Build authentication system with OAuth 2.0 and JWT",
    agent_sequence=["SecurityResearcher", "SecurityAnalyst", "Implementer", "Tester"],
    recall_snippets=["Previous auth implementation notes"],
    assignments=[
        {
            "objective": "Research OAuth 2.0 and JWT standards",
            "expected_output": "Research report with OWASP compliance",
            "tags": ["security", "oauth", "jwt"]
        },
        {
            "objective": "Analyze security requirements and risks",
            "expected_output": "Security risk assessment",
            "tags": ["security", "risk"]
        },
        {
            "objective": "Implement authentication system",
            "expected_output": "Working prototype with tests",
            "tags": ["implementation"]
        },
        {
            "objective": "Create test suite for security validation",
            "expected_output": "Security test cases and validation report",
            "tags": ["testing", "security"]
        }
    ]
)

# Execute dynamically planned workflow
result = await orchestrator.run()
```

### 5. PraisonAI Direct Usage (Individual Agents)

```python
from praisonaiagents import Agent, Task, PraisonAIAgents, GuardrailResult

# Define guardrail validation
def validate_security_output(task_output) -> GuardrailResult:
    content = task_output.raw.lower()
    if "error" in content or "failed" in content:
        return GuardrailResult(
            success=False,
            error="Output contains error indicators"
        )
    if len(content) < 100:
        return GuardrailResult(
            success=False,
            error="Output too short, needs more detail"
        )
    return GuardrailResult(success=True, result=task_output)

# Create agent with self-reflection and guardrails
security_agent = Agent(
    name="SecurityAgent",
    role="Security Expert",
    goal="Analyze security vulnerabilities",
    backstory="Experienced security researcher",
    llm="gpt-4o-mini",
    self_reflect=True,  # Enable self-reflection
    min_reflect=1,  # Minimum reflection iterations
    max_reflect=3,  # Maximum reflection iterations
    guardrail=validate_security_output,  # Validation function
    max_guardrail_retries=3,  # Retry attempts
    tools=[]
)

# Create task
security_task = Task(
    description="Analyze API for SQL injection vulnerabilities",
    expected_output="Detailed security assessment report",
    agent=security_agent
)

# Execute with PraisonAI system
agents_system = PraisonAIAgents(
    agents=[security_agent],
    tasks=[security_task],
    process="sequential",
    verbose=True
)

result = agents_system.start()
```

### 6. Mem0 Direct Usage (Memory Management)

```python
from mem0 import Memory

# Initialize with graph memory
memory = Memory()

# Store conversation context
messages = [
    {"role": "user", "content": "I'm building an API with JWT authentication"},
    {"role": "assistant", "content": "Great! JWT is a secure standard..."}
]
memory.add(messages, user_id="user123", agent_id="security_agent")

# Search relevant memories
memories = memory.search(
    query="JWT authentication best practices",
    user_id="user123",
    limit=5
)

for mem in memories:
    print(f"Score: {mem['score']}, Content: {mem['memory']}")

# Graph-based multi-hop queries
related_memories = memory.search(
    query="related security vulnerabilities",
    user_id="user123",
    filters={"memory_type": "fact"}
)
```

---

## ğŸ“– Key Features

### Orchestrator Highlights

- **Class-Based Architecture**: Modular design with clear separation of concerns
- **Dual Backend Support**: Choose between PraisonAI (simple) or LangGraph (advanced)
- **Three Memory Providers**:
  - **Hybrid** (recommended): Vector + Lexical (BM25) + Graph search with reranking
  - **RAG**: Simple ChromaDB vector search
  - **Mem0**: Graph-based memory with temporal decay
- **DAG Workflow Engine**: Parallel task execution with automatic dependency resolution
- **GraphRAG Tools**: Memory-augmented retrieval with citation tracking
- **Rich CLI**: Real-time progress bars, colored output, Markdown rendering
- **Dynamic Planning**: ToT-based task generation from natural language prompts

### PraisonAI Capabilities

- **100+ LLM Support**: OpenAI, Anthropic, Groq, Ollama, HuggingFace, etc.
- **Self-Reflection**: Configurable 1-3 iteration cycles for quality improvement
- **Guardrails System**: Function-based and LLM-based output validation
- **Execution Patterns**: Sequential, hierarchical, parallel workflows
- **Tool Integration**: DuckDuckGo, Wikipedia, custom tools via decorator
- **Streaming Support**: Real-time token streaming for agent responses
- **100+ Examples**: Comprehensive test suite and usage examples

### Mem0 Features

- **Multi-Level Memory**: User, session, agent scopes with automatic context management
- **Graph Database**: Entity relationships and multi-hop reasoning
- **Temporal Memory**: Automatic decay and importance scoring
- **Cross-Session Persistence**: Maintain context across conversations
- **Performance**: 26% accuracy improvement, 91% faster, 90% token reduction

### Tree-of-Thought Integration

- **Multiple Search Strategies**: BFS, DFS, greedy, beam search
- **StateGraph Generation**: Dynamic workflow planning for LangGraph
- **Configurable Tree**: Depth, branching factor, evaluation samples
- **Automatic Planning**: Integrated with orchestrator router for complex queries

---

## ğŸ—‚ï¸ Project Structure

```
PruebasMultiAgent/
â”œâ”€â”€ orchestrator/              # Scalable orchestration system
â”‚   â”œâ”€â”€ core/                  # Main orchestrator logic
â”‚   â”‚   â”œâ”€â”€ orchestrator.py    # Orchestrator class (925 lines)
â”‚   â”‚   â”œâ”€â”€ config.py          # Configuration management
â”‚   â”‚   â”œâ”€â”€ exceptions.py      # Exception hierarchy
â”‚   â”‚   â””â”€â”€ embedding_utils.py # Embedding utilities
â”‚   â”œâ”€â”€ factories/             # Component factories
â”‚   â”‚   â”œâ”€â”€ agent_factory.py   # Agent creation (502 lines)
â”‚   â”‚   â”œâ”€â”€ task_factory.py    # Task creation
â”‚   â”‚   â”œâ”€â”€ agent_backends.py  # Backend strategies
â”‚   â”‚   â””â”€â”€ graph_factory.py   # LangGraph StateGraph
â”‚   â”œâ”€â”€ memory/                # Memory management
â”‚   â”‚   â”œâ”€â”€ memory_manager.py  # Memory coordinator (218 lines)
â”‚   â”‚   â”œâ”€â”€ document_schema.py # Document schemas
â”‚   â”‚   â””â”€â”€ providers/         # Memory providers
â”‚   â”‚       â”œâ”€â”€ base.py        # IMemoryProvider interface
â”‚   â”‚       â”œâ”€â”€ rag_provider.py
â”‚   â”‚       â”œâ”€â”€ mem0_provider.py
â”‚   â”‚       â””â”€â”€ hybrid_provider.py
â”‚   â”œâ”€â”€ workflow/              # Workflow engine
â”‚   â”‚   â””â”€â”€ workflow_engine.py # DAG execution (594 lines)
â”‚   â”œâ”€â”€ planning/              # Planning systems
â”‚   â”‚   â”œâ”€â”€ tot_planner.py     # Tree-of-Thought
â”‚   â”‚   â””â”€â”€ tot_graph_planner.py
â”‚   â”œâ”€â”€ tools/                 # Agent tools
â”‚   â”‚   â””â”€â”€ graph_rag_tool.py  # GraphRAG retrieval
â”‚   â”œâ”€â”€ cli/                   # CLI interface
â”‚   â”‚   â”œâ”€â”€ main.py            # Chat + info commands
â”‚   â”‚   â”œâ”€â”€ events.py          # Event system
â”‚   â”‚   â””â”€â”€ rich_display.py    # Rich UI
â”‚   â””â”€â”€ ingestion/             # Document processing
â”‚       â”œâ”€â”€ extractors.py      # PDF/text extraction
â”‚       â”œâ”€â”€ metadata_loader.py
â”‚       â””â”€â”€ graph_sync.py      # Neo4j sync
â”‚
â”œâ”€â”€ PraisonAI/                 # Multi-agent framework
â”‚   â”œâ”€â”€ src/praisonai-agents/  # Core agent system
â”‚   â”‚   â”œâ”€â”€ praisonaiagents/   # Main package
â”‚   â”‚   â””â”€â”€ test_*.py          # 100+ test cases
â”‚   â””â”€â”€ examples/              # Usage examples
â”‚
â”œâ”€â”€ mem0/                      # Memory layer
â”‚   â”œâ”€â”€ mem0/                  # Core memory system
â”‚   â””â”€â”€ examples/              # Integration examples
â”‚
â”œâ”€â”€ tree-of-thought-llm/       # Advanced reasoning
â”‚   â””â”€â”€ tot/                   # ToT implementation
â”‚
â”œâ”€â”€ examples/                  # Cross-system examples
â”œâ”€â”€ claudedocs/                # Documentation
â”‚   â””â”€â”€ ORCHESTRATOR_ARCHITECTURE.md  # Detailed architecture
â”œâ”€â”€ pyproject.toml             # Dependencies + installable extras
â”œâ”€â”€ CLAUDE.md                  # Development guide for Claude Code
â””â”€â”€ README.md                  # This file
```

---

## ğŸ“š Documentation

- **[Orchestrator Architecture](claudedocs/ORCHESTRATOR_ARCHITECTURE.md)** - Comprehensive architecture guide
- **[Development Guide (CLAUDE.md)](CLAUDE.md)** - Setup, patterns, and conventions
- **[Engineering Documentation](Engineering%20Documentation%20RAG%20System:%20Complete%20Implementation%20Guide.md)** - RAG system implementation
- **[Multi-Agent Architecture](Engineering_Multi-Agent_Architecture.md)** - System design patterns
- **[ToT Configuration](ToT.md)** - Tree-of-Thought settings

### Component READMEs

- PraisonAI: `PraisonAI/README.md`
- Mem0: `mem0/README.md`
- Tree-of-Thought: `tree-of-thought-llm/README.md`

---

## ğŸ”§ Configuration Reference

### Memory Providers

#### Hybrid Provider (Recommended)

```python
from orchestrator.core.config import MemoryConfig, MemoryProvider, EmbedderConfig

config = MemoryConfig(
    provider=MemoryProvider.HYBRID,
    hybrid_vector_path=".praison/hybrid_chroma",
    hybrid_lexical_db_path=".praison/hybrid_lexical.db",
    embedder=EmbedderConfig(
        provider="openai",
        config={"model": "text-embedding-3-large"}
    ),
    config={
        "neo4j_url": "bolt://localhost:7687",
        "neo4j_user": "neo4j",
        "neo4j_password": "password"
    }
)
```

**Features:**

- Tri-modal search: Vector (semantic) + Lexical (BM25) + Graph (relationships)
- RRF (Reciprocal Rank Fusion) for result combination
- Optional cross-encoder reranking
- Metadata filtering: tags, documents, sections, user_id, run_id

#### Mem0 Provider

```python
config = MemoryConfig(
    provider=MemoryProvider.MEM0,
    embedder=EmbedderConfig(...),
    config={
        "graph_url": "bolt://localhost:7687",
        "vector_provider": "qdrant",
        "qdrant_host": "localhost",
        "qdrant_port": 6333
    }
)
```

**Features:**

- Graph-based entity relationships
- Temporal memory decay
- Multi-scope: user, session, agent
- Cross-session persistence

#### RAG Provider

```python
config = MemoryConfig(
    provider=MemoryProvider.RAG,
    rag_db_path=".praison/memory/chroma_db",
    embedder=EmbedderConfig(...)
)
```

**Features:**

- Simple ChromaDB vector search
- Fast setup, no external dependencies
- Good for prototyping

### LLM Configuration

```bash
# OpenAI (Default)
export OPENAI_API_KEY=your_key_here

# Ollama (Local)
export OPENAI_BASE_URL=http://localhost:11434/v1
export OPENAI_MODEL_NAME=llama2

# Groq (Fast inference)
export OPENAI_BASE_URL=https://api.groq.com/openai/v1
export GROQ_API_KEY=your_groq_key

# Anthropic
export ANTHROPIC_API_KEY=your_anthropic_key
```

### Workflow Configuration

```python
from orchestrator.core.config import ProcessType

config = OrchestratorConfig(
    name="MyWorkflow",
    process="workflow",  # or "sequential", "hierarchical"
    max_iter=25,  # Maximum agent iterations
    async_execution=True,  # Enable async execution
    verbose=1,  # 0=quiet, 1=normal, 2=debug
    user_id="user123",  # For memory filtering
    run_id="project_A"  # For memory scoping
)
```

---

## ğŸ¨ Advanced Patterns

### 1. Multi-Modal Memory Retrieval

```python
from orchestrator import Orchestrator

orchestrator = Orchestrator.from_file("config.yaml")
memory_manager = orchestrator.memory_manager

# Hybrid search with all modalities
results = memory_manager.retrieve_with_graph(
    query="authentication security best practices",
    limit=10,
    tags=["security", "api"],  # Filter by tags
    document_ids=["doc_001", "doc_002"],  # Specific documents
    sections=["authentication", "authorization"],  # Specific sections
    user_id="user123",
    run_id="project_A",
    rerank=True  # Enable cross-encoder reranking
)

# Results include scores and metadata
for result in results:
    print(f"Score: {result['score']:.3f}")
    print(f"Content: {result['content']}")
    print(f"Source: {result['metadata']['document_id']}")
    print(f"Section: {result['metadata']['section']}")
    print("---")
```

### 2. Conditional Workflow Routing

```python
# Task with conditional routing
decision_task = TaskConfig(
    name="security_decision",
    description="Determine security risk level",
    expected_output="Risk level: low|medium|high",
    agent="SecurityAnalyst",
    task_type="decision",
    condition={
        "high": ["emergency_response_task"],
        "medium": ["standard_security_task"],
        "low": ["documentation_task"]
    }
)

# Workflow routes based on decision output
config.tasks.append(decision_task)
```

### 3. Parallel Execution Groups

```python
# Multiple start tasks execute in parallel
config.tasks.extend([
    TaskConfig(
        name="frontend_research",
        agent="FrontendResearcher",
        is_start=True,  # Parallel start
        async_execution=True
    ),
    TaskConfig(
        name="backend_research",
        agent="BackendResearcher",
        is_start=True,  # Parallel start
        async_execution=True
    ),
    TaskConfig(
        name="integration",
        agent="Integrator",
        context=["frontend_research", "backend_research"],  # Waits for both
    )
])
```

### 4. Custom Agent Templates

```python
from orchestrator.factories.agent_factory import BaseAgentTemplate
from orchestrator.core.config import AgentConfig

class SecurityAgentTemplate(BaseAgentTemplate):
    @property
    def agent_type(self) -> str:
        return "security"

    def get_default_config(self) -> AgentConfig:
        return AgentConfig(
            name="SecuritySpecialist",
            role="Security Analysis Expert",
            goal="Identify and assess security vulnerabilities",
            backstory="Expert in OWASP Top 10 and secure coding",
            instructions=(
                "1. Analyze code/architecture for vulnerabilities\n"
                "2. Reference OWASP standards\n"
                "3. Provide severity ratings\n"
                "4. Suggest remediation steps"
            ),
            tools=["graphrag"],
            llm="gpt-4o"
        )

# Register template
factory = AgentFactory()
factory.register_template(SecurityAgentTemplate())

# Use template
security_agent = factory.create_default_agent("security", name="AppSecurityAgent")
```

---

## ğŸ” Performance Benchmarks

### Memory System Performance

| Provider | Search Type        | Latency (p50) | Latency (p95) | Throughput | Index Size (1K docs) |
| -------- | ------------------ | ------------- | ------------- | ---------- | -------------------- |
| RAG      | Vector only        | 30ms          | 80ms          | 250 QPS    | 500MB                |
| Mem0     | Graph + Vector     | 60ms          | 150ms         | 120 QPS    | 1GB                  |
| Hybrid   | Tri-modal + Rerank | 100ms         | 200ms         | 90 QPS     | 1.5GB                |

### Workflow Engine Performance

| Configuration        | Tasks | Agents | Total Time | Parallel Efficiency |
| -------------------- | ----- | ------ | ---------- | ------------------- |
| Sequential           | 20    | 5      | 180s       | 1.0x (baseline)     |
| Parallel (5 workers) | 20    | 5      | 45s        | 4.0x                |
| Mixed (adaptive)     | 20    | 5      | 55s        | 3.3x                |

### Scaling Characteristics

- **Documents**: Tested up to 10,000 documents with hybrid provider
- **Agents**: Optimal range 8-12 agents per workflow
- **Tasks**: Optimal range 20-50 tasks per workflow
- **Memory Retrieval**: <200ms p95 for 10 results with reranking
- **Workflow Duration**: 10s-30min (primarily LLM latency)

---

## ğŸ› ï¸ Troubleshooting

### Common Issues

#### 1. "Memory provider not initialized"

**Symptoms:** Error when starting orchestrator or running queries

**Solutions:**

```bash
# Check environment variables
echo $NEO4J_URL
echo $OPENAI_API_KEY

# Verify Neo4j is running
docker ps | grep neo4j

# Test provider health
python -m orchestrator.cli memory-info --memory-provider hybrid

# Alternative: Use RAG provider (no Neo4j)
python -m orchestrator.cli chat --memory-provider rag
```

#### 2. "Circular dependencies detected"

**Symptoms:** ValidationError during orchestrator initialization

**Solutions:**

```python
# Validate configuration before execution
from orchestrator import OrchestratorConfig

config = OrchestratorConfig.from_file("config.yaml")
config.validate()  # Raises ValidationError with details

# Check task dependencies
for task in config.tasks:
    print(f"{task.name} depends on: {task.context}")
```

#### 3. "LangGraph components not available"

**Symptoms:** ImportError or fallback to PraisonAI mode

**Solutions:**

```bash
# Install LangGraph dependencies
pip install langgraph langchain-core langchain-community

# Verify installation
python -c "from langgraph.graph import StateGraph; print('OK')"

# Check backend mode
python -c "
from orchestrator.core.orchestrator import USING_LANGGRAPH
print(f'LangGraph enabled: {USING_LANGGRAPH}')
"
```

#### 4. "GraphRAG tool not found"

**Symptoms:** Agent complains about missing "graphrag" tool

**Solutions:**

```python
# Ensure tool is created before agent initialization
orchestrator.initialize()
graphrag_tool = orchestrator.create_graph_tool(
    user_id="user123",
    run_id="project_A"
)

# Verify tool attachment
for agent in orchestrator.agents.values():
    print(f"{agent.name} tools: {agent.tools}")
```

### Debug Mode

```bash
# Enable verbose logging
export ORCHESTRATOR_VERBOSE=2
python -m orchestrator.cli chat --verbose

# Check component health
python -m orchestrator.cli memory-info --memory-provider hybrid

# Validate configuration
python -c "
from orchestrator import Orchestrator
orch = Orchestrator.from_file('config.yaml')
print(orch.get_system_info())
"
```

---

## ğŸ—ºï¸ Roadmap

### Q1 2025

- [ ] **Observability**: OpenTelemetry integration, Prometheus metrics
- [ ] **Kubernetes Operator**: Automated deployment and scaling
- [ ] **REST API Server**: OpenAPI spec with authentication
- [ ] **Advanced Routing**: ML-based query classification

### Q2 2025

- [ ] **Multi-Tenant Support**: Isolated memory and execution contexts
- [ ] **Human-in-the-Loop**: Approval gates and interactive workflows
- [ ] **Distributed Caching**: Redis integration for memory layer
- [ ] **Sub-Workflow Composition**: Reusable workflow components

### Q3 2025

- [ ] **LangSmith Integration**: Enhanced monitoring and debugging
- [ ] **Workflow Visualization**: Real-time DAG rendering dashboard
- [ ] **Advanced Memory**: Automatic index optimization, query optimization
- [ ] **Custom LLM Backends**: Support for custom model integrations

---

## ğŸ¤ Contributing

Contributions are welcome! Please see individual component directories for specific contribution guidelines:

- PraisonAI: `PraisonAI/CONTRIBUTING.md`
- Mem0: `mem0/CONTRIBUTING.md`
- Orchestrator: Create issues or PRs for orchestrator improvements

### Development Setup

```bash
# Clone with submodules
git clone --recurse-submodules <repository-url>

# Install dev dependencies
uv pip install -e .[all-mem0]

# Run tests
python orchestrator/factories/tests/test_agent_factory.py
python PraisonAI/src/praisonai-agents/test_multi_agents.py

# Lint
ruff check .
ruff format .
```

---

## ğŸ“„ License

This project integrates multiple components with their respective licenses:

- **PraisonAI**: MIT License
- **Mem0**: Apache 2.0 License
- **Tree-of-Thought-LLM**: MIT License
- **Orchestrator**: MIT License

See individual component directories for detailed license information.

---

## ğŸ™ Acknowledgments

This framework integrates and builds upon these excellent open-source projects:

- **[PraisonAI](https://github.com/MervinPraison/PraisonAI)** - Multi-agent AI framework
- **[Mem0](https://github.com/mem0ai/mem0)** - Memory layer for AI
- **[Tree-of-Thought-LLM](https://github.com/princeton-nlp/tree-of-thought-llm)** - Advanced reasoning
- **[LangGraph](https://github.com/langchain-ai/langgraph)** - StateGraph workflows
- **[ChromaDB](https://www.trychroma.com/)** - Vector database
- **[Neo4j](https://neo4j.com/)** - Graph database
- **[Rich](https://github.com/Textualize/rich)** - Terminal UI

---

## ğŸ“§ Support

- **Documentation**: See `/claudedocs` and component READMEs
- **Issues**: Create issues in this repository
- **Discussions**: Use GitHub Discussions for questions
- **Development**: See `CLAUDE.md` for development guide

---

**Built with â¤ï¸ for the AI agent community**
