"""
Graph Compiler: Bridge between ToT StateGraph specifications and GraphFactory.

This module provides the translation layer that converts StateGraphSpec objects
(generated by Tree-of-Thought planning) into executable LangGraph StateGraphs
via the GraphFactory system.
"""

import logging
from typing import Dict, List, Any, Optional, Callable, Set, Tuple
from dataclasses import asdict

from .graph_specifications import (
    StateGraphSpec, GraphNodeSpec, GraphEdgeSpec, NodeType, EdgeType,
    RoutingStrategy, GraphCondition, ParallelGroup
)
from ..integrations.langchain_integration import (
    StateGraph, START, END, OrchestratorState, LangChainAgent,
    HumanMessage, AIMessage, is_available
)
from ..factories.graph_factory import GraphFactory
from ..factories.agent_factory import AgentFactory
from ..core.config import AgentConfig
from ..core.exceptions import GraphCreationError

logger = logging.getLogger(__name__)


class GraphCompiler:
    """
    Compiler that transforms ToT StateGraph specifications into executable LangGraph StateGraphs.
    
    This class bridges the gap between the declarative graph specifications generated
    by Tree-of-Thought planning and the executable StateGraph objects required by
    the LangGraph runtime.
    """
    
    def __init__(self, agent_factory: Optional[AgentFactory] = None):
        """Initialize the graph compiler."""
        if not is_available():
            raise GraphCreationError("LangChain components not available for graph compilation")
        
        self.agent_factory = agent_factory or AgentFactory()
        self.graph_factory = GraphFactory(self.agent_factory)
        
        # Compilation state
        self._agent_cache: Dict[str, LangChainAgent] = {}
        self._node_functions: Dict[str, Callable] = {}
        self._compiled_graphs: Dict[str, StateGraph] = {}
        
        logger.info("GraphCompiler initialized with LangGraph support")
    
    def compile_graph_spec(
        self,
        graph_spec: StateGraphSpec,
        agent_configs: List[AgentConfig],
        validation_mode: bool = True
    ) -> StateGraph:
        """
        Compile a StateGraphSpec into an executable LangGraph StateGraph.
        
        Args:
            graph_spec: The graph specification to compile
            agent_configs: Available agent configurations
            validation_mode: Whether to perform validation before compilation
            
        Returns:
            Compiled StateGraph ready for execution
            
        Raises:
            GraphCreationError: If compilation fails
        """
        try:
            logger.info(f"Compiling graph specification: {graph_spec.name}")
            
            # Validate graph specification if requested
            if validation_mode:
                validation_errors = graph_spec.validate()
                if validation_errors:
                    raise GraphCreationError(f"Graph validation failed: {validation_errors}")
            
            # Create agent configurations mapping
            agent_config_map = {config.name: config for config in agent_configs}
            
            # Initialize StateGraph with orchestrator state
            workflow = StateGraph(OrchestratorState)
            
            # Compile nodes
            self._compile_nodes(workflow, graph_spec, agent_config_map)
            
            # Compile edges
            self._compile_edges(workflow, graph_spec)
            
            # Set entry and exit points
            self._set_entry_exit_points(workflow, graph_spec)
            
            # Handle parallel groups
            self._handle_parallel_groups(workflow, graph_spec)
            
            # Cache compiled graph
            self._compiled_graphs[graph_spec.name] = workflow
            
            logger.info(f"Successfully compiled graph '{graph_spec.name}' with "
                       f"{len(graph_spec.nodes)} nodes and {len(graph_spec.edges)} edges")
            
            return workflow
            
        except Exception as e:
            logger.error(f"Failed to compile graph specification: {str(e)}")
            raise GraphCreationError(f"Graph compilation failed: {str(e)}")
    
    def _compile_nodes(
        self,
        workflow: StateGraph,
        graph_spec: StateGraphSpec,
        agent_config_map: Dict[str, AgentConfig]
    ) -> None:
        """Compile nodes from graph specification."""
        for node_spec in graph_spec.nodes:
            try:
                node_function = self._create_node_function(node_spec, agent_config_map)
                workflow.add_node(node_spec.name, node_function)
                self._node_functions[node_spec.name] = node_function
                
                logger.debug(f"Compiled node: {node_spec.name} ({node_spec.type.value})")
                
            except Exception as e:
                logger.error(f"Failed to compile node {node_spec.name}: {str(e)}")
                raise GraphCreationError(f"Node compilation failed for {node_spec.name}: {str(e)}")
    
    def _create_node_function(
        self,
        node_spec: GraphNodeSpec,
        agent_config_map: Dict[str, AgentConfig]
    ) -> Callable:
        """Create a node function based on the node specification."""
        
        if node_spec.type == NodeType.START:
            return self._create_start_function(node_spec)
        elif node_spec.type == NodeType.END:
            return self._create_end_function(node_spec)
        elif node_spec.type == NodeType.AGENT:
            return self._create_agent_function(node_spec, agent_config_map)
        elif node_spec.type == NodeType.ROUTER:
            return self._create_router_function(node_spec)
        elif node_spec.type == NodeType.CONDITION:
            return self._create_condition_function(node_spec)
        elif node_spec.type == NodeType.PARALLEL:
            return self._create_parallel_function(node_spec)
        elif node_spec.type == NodeType.AGGREGATOR:
            return self._create_aggregator_function(node_spec)
        else:
            raise GraphCreationError(f"Unsupported node type: {node_spec.type}")
    
    def _create_start_function(self, node_spec: GraphNodeSpec) -> Callable:
        """Create a start node function."""
        def start_function(state: OrchestratorState) -> Dict[str, Any]:
            logger.debug(f"Executing start node: {node_spec.name}")

            # Build update dict with only modified fields
            updates = {
                "current_node": node_spec.name,
                "execution_path": state.execution_path + [node_spec.name],
                "node_outputs": {**state.node_outputs, node_spec.name: "Workflow initialized"},
                "current_iteration": 0
            }

            # Add start message if not present
            if not state.messages:
                updates["messages"] = [HumanMessage(content=state.input_prompt)]

            return updates

        return start_function
    
    def _create_end_function(self, node_spec: GraphNodeSpec) -> Callable:
        """Create an end node function."""
        def end_function(state: OrchestratorState) -> Dict[str, Any]:
            logger.debug(f"Executing end node: {node_spec.name}")

            # Build update dict with only modified fields
            updates = {
                "current_node": node_spec.name,
                "execution_path": state.execution_path + [node_spec.name],
                "node_outputs": {**state.node_outputs, node_spec.name: "Workflow completed"}
            }

            # Generate final output if not already present
            if not state.final_output and state.agent_outputs:
                final_output = self._generate_final_output(state)
                updates["final_output"] = final_output
                updates["messages"] = [AIMessage(content=final_output)]

            logger.info(f"Workflow completed at node: {node_spec.name}")

            return updates

        return end_function
    
    def _create_agent_function(
        self,
        node_spec: GraphNodeSpec,
        agent_config_map: Dict[str, AgentConfig]
    ) -> Callable:
        """Create an agent execution function."""

        # Get or create agent
        agent_name = node_spec.agent
        if not agent_name or agent_name not in agent_config_map:
            raise GraphCreationError(f"Agent '{agent_name}' not found in configuration")

        agent_config = agent_config_map[agent_name]

        # Cache agent creation
        if agent_name not in self._agent_cache:
            self._agent_cache[agent_name] = self.agent_factory.create_agent(agent_config)

        agent = self._agent_cache[agent_name]

        def agent_function(state: OrchestratorState) -> Dict[str, Any]:
            try:
                logger.debug(f"Executing agent node: {node_spec.name} (agent: {agent_name})")

                # Build task description
                task_description = self._build_task_description(node_spec, state)

                # Execute agent
                result = agent.execute(task_description, {"state": asdict(state)})

                logger.debug(f"Agent {agent_name} completed execution in node {node_spec.name}")

                # Return ONLY modified fields
                return {
                    "agent_outputs": {**state.agent_outputs, agent_name: result},
                    "node_outputs": {**state.node_outputs, node_spec.name: result},
                    "completed_agents": state.completed_agents + [agent_name],
                    "current_iteration": state.current_iteration + 1,
                    "execution_path": state.execution_path + [node_spec.name],
                    "current_node": node_spec.name,
                    "messages": [AIMessage(content=result)]  # add_messages will append
                }

            except Exception as e:
                error_msg = f"Agent {agent_name} failed in node {node_spec.name}: {str(e)}"
                logger.error(error_msg)
                return {
                    "errors": state.errors + [{
                        "node": node_spec.name,
                        "agent": agent_name,
                        "message": error_msg,
                        "recoverable": False
                    }],
                    "node_outputs": {**state.node_outputs, node_spec.name: error_msg},
                    "error_state": error_msg
                }

        return agent_function
    
    def _create_router_function(self, node_spec: GraphNodeSpec) -> Callable:
        """Create a routing decision function."""
        def router_function(state: OrchestratorState) -> Dict[str, Any]:
            logger.debug(f"Executing router node: {node_spec.name}")

            # Implement routing logic based on strategy
            if node_spec.routing_strategy == RoutingStrategy.LLM_BASED:
                routing_result = self._llm_based_routing(node_spec, state)
            elif node_spec.routing_strategy == RoutingStrategy.STATE_BASED:
                routing_result = self._state_based_routing(node_spec, state)
            else:
                routing_result = self._rule_based_routing(node_spec, state)

            route = routing_result.get("route")

            # Return ONLY modified fields
            return {
                "current_node": node_spec.name,
                "execution_path": state.execution_path + [node_spec.name],
                "router_decision": routing_result,
                "current_route": route,
                "node_outputs": {**state.node_outputs, node_spec.name: f"Routed to: {route}"}
            }

        return router_function
    
    def _create_condition_function(self, node_spec: GraphNodeSpec) -> Callable:
        """Create a conditional logic function."""
        def condition_function(state: OrchestratorState) -> Dict[str, Any]:
            logger.debug(f"Executing condition node: {node_spec.name}")

            # Evaluate conditions
            results = []
            for condition in node_spec.entry_conditions:
                result = condition.evaluate(state)
                results.append(result)

            # Store condition results
            condition_result = all(results) if results else True

            # Build condition_results dict
            updated_condition_results = state.condition_results.copy() if state.condition_results else {}
            updated_condition_results[node_spec.name] = condition_result

            # Return ONLY modified fields
            return {
                "current_node": node_spec.name,
                "execution_path": state.execution_path + [node_spec.name],
                "node_outputs": {**state.node_outputs, node_spec.name: f"Condition result: {condition_result}"},
                "condition_results": updated_condition_results
            }

        return condition_function
    
    def _create_parallel_function(self, node_spec: GraphNodeSpec) -> Callable:
        """Create a parallel coordination function."""
        def parallel_function(state: OrchestratorState) -> Dict[str, Any]:
            logger.debug(f"Executing parallel coordinator: {node_spec.name}")

            # Return ONLY modified fields
            return {
                "current_node": node_spec.name,
                "execution_path": state.execution_path + [node_spec.name],
                "parallel_execution_active": True,
                "node_outputs": {**state.node_outputs, node_spec.name: "Parallel execution initiated"}
            }

        return parallel_function
    
    def _create_aggregator_function(self, node_spec: GraphNodeSpec) -> Callable:
        """Create a results aggregation function."""
        def aggregator_function(state: OrchestratorState) -> Dict[str, Any]:
            logger.debug(f"Executing aggregator node: {node_spec.name}")

            # Aggregate results from parallel execution
            if state.parallel_execution_active:
                aggregated_result = self._aggregate_parallel_results(state)
                output_message = aggregated_result
                parallel_active = False
            else:
                output_message = "No parallel results to aggregate"
                parallel_active = state.parallel_execution_active

            # Return ONLY modified fields
            return {
                "current_node": node_spec.name,
                "execution_path": state.execution_path + [node_spec.name],
                "node_outputs": {**state.node_outputs, node_spec.name: output_message},
                "parallel_execution_active": parallel_active
            }

        return aggregator_function
    
    def _compile_edges(self, workflow: StateGraph, graph_spec: StateGraphSpec) -> None:
        """Compile edges from graph specification."""
        for edge_spec in graph_spec.edges:
            try:
                if edge_spec.type == EdgeType.DIRECT:
                    workflow.add_edge(edge_spec.from_node, edge_spec.to_node)
                elif edge_spec.type == EdgeType.CONDITIONAL:
                    condition_func = self._create_edge_condition(edge_spec)
                    workflow.add_conditional_edges(edge_spec.from_node, condition_func)
                else:
                    # For other edge types, treat as direct for now
                    workflow.add_edge(edge_spec.from_node, edge_spec.to_node)
                
                logger.debug(f"Compiled edge: {edge_spec.from_node} -> {edge_spec.to_node}")
                
            except Exception as e:
                logger.error(f"Failed to compile edge {edge_spec.from_node}->{edge_spec.to_node}: {str(e)}")
                # Continue with other edges rather than failing completely
    
    def _create_edge_condition(self, edge_spec: GraphEdgeSpec) -> Callable:
        """Create a conditional edge function."""
        def edge_condition(state: OrchestratorState) -> str:
            if edge_spec.condition:
                condition_result = edge_spec.condition.evaluate(state)
                if condition_result:
                    return edge_spec.to_node
                else:
                    # Return alternative route or stay at current node
                    return END  # or another default route
            else:
                return edge_spec.to_node
        
        return edge_condition
    
    def _set_entry_exit_points(self, workflow: StateGraph, graph_spec: StateGraphSpec) -> None:
        """Set entry and exit points for the graph."""
        # Set entry point
        if graph_spec.entry_point:
            workflow.set_entry_point(graph_spec.entry_point)
        else:
            # Find start node or use first node
            start_nodes = [node.name for node in graph_spec.nodes if node.type == NodeType.START]
            if start_nodes:
                workflow.set_entry_point(start_nodes[0])
            elif graph_spec.nodes:
                workflow.set_entry_point(graph_spec.nodes[0].name)
        
        # Add edges to END for exit points
        for exit_point in graph_spec.exit_points:
            if exit_point != "end":  # Avoid self-reference
                workflow.add_edge(exit_point, END)
    
    def _handle_parallel_groups(self, workflow: StateGraph, graph_spec: StateGraphSpec) -> None:
        """Handle parallel execution groups."""
        for parallel_group in graph_spec.parallel_groups:
            logger.debug(f"Processing parallel group: {parallel_group.group_id}")
            # Parallel group handling would be complex and might require
            # specialized LangGraph features or custom implementation
            # For now, we log the presence of parallel groups
    
    def _build_task_description(self, node_spec: GraphNodeSpec, state: OrchestratorState) -> str:
        """Build task description for agent execution."""
        description_parts = []
        
        # Add node objective
        if node_spec.objective:
            description_parts.append(f"Objective: {node_spec.objective}")
        
        # Add expected output
        if node_spec.expected_output:
            description_parts.append(f"Expected Output: {node_spec.expected_output}")
        
        # Add context from state
        if state.memory_context:
            description_parts.append(f"Context: {state.memory_context}")
        
        # Add user prompt
        description_parts.append(f"User Request: {state.input_prompt}")
        
        # Add execution context
        if state.completed_agents:
            description_parts.append(f"Previous Agents: {', '.join(state.completed_agents)}")
        
        return "\n\n".join(description_parts)
    
    def _llm_based_routing(self, node_spec: GraphNodeSpec, state: OrchestratorState) -> Dict[str, Any]:
        """Implement LLM-based routing logic."""
        # This would use an LLM to make routing decisions
        # For now, return a default route
        return {"route": "default", "method": "llm_based", "confidence": 0.8}
    
    def _state_based_routing(self, node_spec: GraphNodeSpec, state: OrchestratorState) -> Dict[str, Any]:
        """Implement state-based routing logic."""
        # Route based on current state conditions
        if state.error_state:
            return {"route": "error_handling", "method": "state_based"}
        elif len(state.completed_agents) > 2:
            return {"route": "completion", "method": "state_based"}
        else:
            return {"route": "continue", "method": "state_based"}
    
    def _rule_based_routing(self, node_spec: GraphNodeSpec, state: OrchestratorState) -> Dict[str, Any]:
        """Implement rule-based routing logic."""
        # Simple keyword-based routing
        prompt_lower = state.input_prompt.lower()
        
        if any(word in prompt_lower for word in ["quick", "simple"]):
            return {"route": "quick", "method": "rule_based"}
        elif any(word in prompt_lower for word in ["research", "search"]):
            return {"route": "research", "method": "rule_based"}
        elif any(word in prompt_lower for word in ["analyze", "analysis"]):
            return {"route": "analysis", "method": "rule_based"}
        else:
            return {"route": "default", "method": "rule_based"}
    
    def _generate_final_output(self, state: OrchestratorState) -> str:
        """Generate final output from agent results."""
        if not state.agent_outputs:
            return "No results generated."
        
        # Simple concatenation - could be enhanced with LLM summarization
        results = []
        for agent, output in state.agent_outputs.items():
            results.append(f"**{agent}**: {output}")
        
        return "\n\n".join(results)
    
    def _aggregate_parallel_results(self, state: OrchestratorState) -> str:
        """Aggregate results from parallel execution."""
        # Simple aggregation strategy
        parallel_outputs = [output for output in state.agent_outputs.values()]
        return f"Aggregated {len(parallel_outputs)} parallel results"
    
    def get_compiled_graph(self, graph_name: str) -> Optional[StateGraph]:
        """Get a compiled graph by name."""
        return self._compiled_graphs.get(graph_name)
    
    def clear_cache(self) -> None:
        """Clear all compilation caches."""
        self._agent_cache.clear()
        self._node_functions.clear()
        self._compiled_graphs.clear()
        logger.info("GraphCompiler caches cleared")


# Convenience functions for direct compilation
def compile_tot_graph(
    graph_spec: StateGraphSpec,
    agent_configs: List[AgentConfig],
    agent_factory: Optional[AgentFactory] = None
) -> StateGraph:
    """
    Convenience function to compile a ToT graph specification.
    
    Args:
        graph_spec: The graph specification to compile
        agent_configs: Available agent configurations
        agent_factory: Optional custom agent factory
        
    Returns:
        Compiled StateGraph ready for execution
    """
    compiler = GraphCompiler(agent_factory)
    workflow = compiler.compile_graph_spec(graph_spec, agent_configs)
    return workflow.compile()


def compile_and_validate_graph(
    graph_spec: StateGraphSpec,
    agent_configs: List[AgentConfig],
    agent_factory: Optional[AgentFactory] = None
) -> Tuple[StateGraph, List[str]]:
    """
    Compile a graph specification with validation.
    
    Args:
        graph_spec: The graph specification to compile
        agent_configs: Available agent configurations
        agent_factory: Optional custom agent factory
        
    Returns:
        Tuple of (compiled_graph, validation_errors)
    """
    # Validate first
    validation_errors = graph_spec.validate()
    
    # Compile if validation passes
    if not validation_errors:
        compiler = GraphCompiler(agent_factory)
        workflow = compiler.compile_graph_spec(graph_spec, agent_configs)
        return workflow.compile(), []
    else:
        return None, validation_errors


# Export main classes and functions
__all__ = [
    "GraphCompiler",
    "compile_tot_graph",
    "compile_and_validate_graph"
]